# from mcp.server.fastmcp import FastMCP

# from mcp.shared.exceptions import McpError
# from mcp.types import TextContent, EmbeddedResource, INTERNAL_ERROR, Prompt, PromptArgument, Resource  
# import pandas as pd
# import numpy as np
# import scipy
# import sklearn
# import statsmodels.api as sm
# from io import StringIO
# import sys
# import os
# from typing import Optional, List

# mcp = FastMCP(name="mcp_server_ds", host="127.0.0.1", port=8003)

# # In-memory data store for loaded DataFrames
# _dataframes = {}
# _df_count = 0
# _notes: list[str] = []

# def _next_df_name():
#     global _df_count
#     _df_count += 1
#     return f"df_{_df_count}"

# @mcp.tool()
# def load_csv(csv_path: str, df_name: Optional[str] = None) -> list:
#     """Load a local CSV file into a DataFrame."""
#     global _dataframes, _notes
#     if not df_name:
#         df_name = _next_df_name()
#     try:
#         _dataframes[df_name] = pd.read_csv(csv_path)
#     except UnicodeDecodeError:
#         _dataframes[df_name] = pd.read_csv(csv_path, encoding="latin1")
#     except Exception as e:
#         raise McpError(INTERNAL_ERROR, f"Error loading CSV: {str(e)}") from e
#     _notes.append(f"Successfully loaded CSV into dataframe '{df_name}'")
#     return [TextContent(type="text", text=f"Successfully loaded CSV into dataframe '{df_name}'")]

# @mcp.tool()
# def run_script(script: str, save_to_memory: Optional[List[str]] = None) -> list:
#     """Execute a Python script for data analytics tasks."""
#     global _dataframes, _notes
#     local_dict = {**_dataframes}
#     try:
#         stdout_capture = StringIO()
#         old_stdout = sys.stdout
#         sys.stdout = stdout_capture
#         _notes.append(f"Running script: \n{script}")
#         exec(script, {'pd': pd, 'np': np, 'scipy': scipy, 'sklearn': sklearn, 'statsmodels': sm}, local_dict)
#         std_out_script = stdout_capture.getvalue()
#     except Exception as e:
#         raise McpError(INTERNAL_ERROR, f"Error running script: {str(e)}") from e
#     finally:
#         sys.stdout = old_stdout
#     if save_to_memory:
#         for df_name in save_to_memory:
#             _notes.append(f"Saving dataframe '{df_name}' to memory")
#             _dataframes[df_name] = local_dict.get(df_name)
#     output = std_out_script if std_out_script else "No output"
#     _notes.append(f"Result: {output}")
#     return [TextContent(type="text", text=f"print out result: {output}")]

# @mcp.tool()
# def get_notes() -> list:
#     """Return the notes generated by the data exploration server."""
#     global _notes
#     return [TextContent(type="text", text="\n".join(_notes))]

# PROMPT_TEMPLATE = """
# You are a professional Data Scientist tasked with performing exploratory data analysis on a dataset. Your goal is to provide insightful analysis while ensuring stability and manageable result sizes.

# First, load the CSV file from the following path:

# <csv_path>
# {csv_path}
# </csv_path>

# Your analysis should focus on the following topic:

# <analysis_topic>
# {topic}
# </analysis_topic>

# You have access to the following tools for your analysis:
# 1. load_csv: Use this to load the CSV file.
# 2. run-script: Use this to execute Python scripts on the MCP server.

# Please follow these steps carefully:

# 1. Load the CSV file using the load_csv tool.

# 2. Explore the dataset. Provide a brief summary of its structure, including the number of rows, columns, and data types. Wrap your exploration process in <dataset_exploration> tags, including:
#    - List of key statistics about the dataset
#    - Potential challenges you foresee in analyzing this data

# 3. Wrap your thought process in <analysis_planning> tags:
#    Analyze the dataset size and complexity:
#    - How many rows and columns does it have?
#    - Are there any potential computational challenges based on the data types or volume?
#    - What kind of questions would be appropriate given the dataset's characteristics and the analysis topic?
#    - How can we ensure that our questions won't result in excessively large outputs?

#    Based on this analysis:
#    - List 10 potential questions related to the analysis topic
#    - Evaluate each question against the following criteria:
#      * Directly related to the analysis topic
#      * Can be answered with reasonable computational effort
#      * Will produce manageable result sizes
#      * Provides meaningful insights into the data
#    - Select the top 5 questions that best meet all criteria

# 4. List the 5 questions you've selected, ensuring they meet the criteria outlined above.

# 5. For each question, follow these steps:
#    a. Wrap your thought process in <analysis_planning> tags:
#       - How can I structure the Python script to efficiently answer this question?
#       - What data preprocessing steps are necessary?
#       - How can I limit the output size to ensure stability?
#       - What type of visualization would best represent the results?
#       - Outline the main steps the script will follow
   
#    b. Write a Python script to answer the question. Include comments explaining your approach and any measures taken to limit output size.
   
#    c. Use the run_script tool to execute your Python script on the MCP server.
   
#    d. Render the results returned by the run-script tool as a chart using plotly.js (prefer loading from cdnjs.cloudflare.com). Do not use react or recharts, and do not read the original CSV file directly. Provide the plotly.js code to generate the chart.

# 6. After completing the analysis for all 5 questions, provide a brief summary of your findings and any overarching insights gained from the data.

# Remember to prioritize stability and manageability in your analysis. If at any point you encounter potential issues with large result sets, adjust your approach accordingly.

# Please begin your analysis by loading the CSV file and providing an initial exploration of the dataset.
# """

# @mcp.prompt()
# def explore_data_prompt():
#     print("Registering explore_data_prompt")  # Add this line
#     return [
#         Prompt(
#             name="explore-data",
#             description="A prompt to explore a csv dataset as a data scientist",
#             arguments=[
#                 PromptArgument(name="csv_path", description="The path to the csv file", required=True),
#                 PromptArgument(name="topic", description="The topic the data exploration need to focus on", required=False),
#             ],
#         )
#     ]

# @mcp.resource("data-exploration://notes")
# def notes_resource():
#     return [
#         Resource(
#             uri="data-exploration://notes",
#             name="Data Exploration Notes",
#             description="Notes generated by the data exploration server",
#             mimeType="text/plain"
#         )
#     ]

# if __name__ == "__main__":
#     mcp.run(transport="streamable-http")

from mcp.server.fastmcp import FastMCP

from mcp.shared.exceptions import McpError
from mcp.types import TextContent, EmbeddedResource, INTERNAL_ERROR, Prompt, PromptArgument, Resource  
import pandas as pd
import numpy as np
import scipy
import sklearn
import statsmodels.api as sm
from io import StringIO
import sys
import os
from typing import Optional, List
from pydantic import BaseModel

mcp = FastMCP(name="mcp_server_ds", host="127.0.0.1", port=8003)

# In-memory data store for loaded DataFrames
_dataframes = {}
_df_count = 0
_notes: list[str] = []

def _next_df_name():
    global _df_count
    _df_count += 1
    return f"df_{_df_count}"



class LoadCsvArgs(BaseModel):
    csv_path: str
    df_name: Optional[str] = None

@mcp.tool()
def load_csv(args: LoadCsvArgs) -> list:
    """Load a local CSV file into a DataFrame."""
    global _dataframes, _notes
    csv_path = args.csv_path
    df_name = args.df_name
    if not df_name:
        df_name = _next_df_name()
    try:
        _dataframes[df_name] = pd.read_csv(csv_path)
    except UnicodeDecodeError:
        _dataframes[df_name] = pd.read_csv(csv_path, encoding="latin1")
    except Exception as e:
        raise McpError(INTERNAL_ERROR, f"Error loading CSV: {str(e)}") from e
    _notes.append(f"Successfully loaded CSV into dataframe '{df_name}'")
    return [TextContent(type="text", text=f"Successfully loaded CSV into dataframe '{df_name}'")]

class RunScriptArgs(BaseModel):
    script: str
    save_to_memory: Optional[List[str]] = None

@mcp.tool()
def run_script(args: RunScriptArgs) -> list:
    """Execute a Python script for data analytics tasks."""
    global _dataframes, _notes
    script = args.script
    save_to_memory = args.save_to_memory
    local_dict = {**_dataframes}
    try:
        stdout_capture = StringIO()
        old_stdout = sys.stdout
        sys.stdout = stdout_capture
        _notes.append(f"Running script: \n{script}")
        exec(script, {'pd': pd, 'np': np, 'scipy': scipy, 'sklearn': sklearn, 'statsmodels': sm}, local_dict)
        std_out_script = stdout_capture.getvalue()
    except Exception as e:
        raise McpError(INTERNAL_ERROR, f"Error running script: {str(e)}") from e
    finally:
        sys.stdout = old_stdout
    if save_to_memory:
        for df_name in save_to_memory:
            _notes.append(f"Saving dataframe '{df_name}' to memory")
            _dataframes[df_name] = local_dict.get(df_name)
    output = std_out_script if std_out_script else "No output"
    _notes.append(f"Result: {output}")

    # --- Detect Plotly JSON in output and return as code block ---
    import re
    plotly_json = None
    # Look for code block with JSON
    match = re.search(r"```json\s*({[\s\S]*?})\s*```", output)
    if match:
        plotly_json = match.group(0)
    else:
        # Look for inline JSON
        match = re.search(r'({\s*"data"\s*:\s*\[.*?\][\s\S]*?})', output)
        if match:
            plotly_json = f'```json\n{match.group(1)}\n```'

    if plotly_json:
        return [
            TextContent(type="text", text="Here is your chart:\n" + plotly_json)
        ]
    else:
        return [
            TextContent(type="text", text=f"print out result: {output}")
        ]

@mcp.tool()
def get_notes() -> list:
    """Return the notes generated by the data exploration server."""
    global _notes
    return [TextContent(type="text", text="\n".join(_notes))]

PROMPT_TEMPLATE = """
You are a professional Data Scientist tasked with performing exploratory data analysis on a dataset. Your goal is to provide insightful analysis while ensuring stability and manageable result sizes.

First, load the CSV file from the following path:

<csv_path>
{csv_path}
</csv_path>

Your analysis should focus on the following topic:

<analysis_topic>
{topic}
</analysis_topic>

You have access to the following tools for your analysis:
1. load_csv: Use this to load the CSV file.
2. run-script: Use this to execute Python scripts on the MCP server.

Please follow these steps carefully:

1. Load the CSV file using the load_csv tool.

2. Explore the dataset. Provide a brief summary of its structure, including the number of rows, columns, and data types. Wrap your exploration process in <dataset_exploration> tags, including:
   - List of key statistics about the dataset
   - Potential challenges you foresee in analyzing this data

3. Wrap your thought process in <analysis_planning> tags:
   Analyze the dataset size and complexity:
   - How many rows and columns does it have?
   - Are there any potential computational challenges based on the data types or volume?
   - What kind of questions would be appropriate given the dataset's characteristics and the analysis topic?
   - How can we ensure that our questions won't result in excessively large outputs?

   Based on this analysis:
   - List 10 potential questions related to the analysis topic
   - Evaluate each question against the following criteria:
     * Directly related to the analysis topic
     * Can be answered with reasonable computational effort
     * Will produce manageable result sizes
     * Provides meaningful insights into the data
   - Select the top 5 questions that best meet all criteria

4. List the 5 questions you've selected, ensuring they meet the criteria outlined above.

5. For each question, follow these steps:
   a. Wrap your thought process in <analysis_planning> tags:
      - How can I structure the Python script to efficiently answer this question?
      - What data preprocessing steps are necessary?
      - How can I limit the output size to ensure stability?
      - What type of visualization would best represent the results?
      - Outline the main steps the script will follow
   
   b. Write a Python script to answer the question. Include comments explaining your approach and any measures taken to limit output size.
   
   c. Use the run_script tool to execute your Python script on the MCP server.
   
   d. Render the results returned by the run-script tool as a chart using plotly.js (prefer loading from cdnjs.cloudflare.com). Do not use react or recharts, and do not read the original CSV file directly. Provide the plotly.js code to generate the chart.

6. After completing the analysis for all 5 questions, provide a brief summary of your findings and any overarching insights gained from the data.

Remember to prioritize stability and manageability in your analysis. If at any point you encounter potential issues with large result sets, adjust your approach accordingly.

Please begin your analysis by loading the CSV file and providing an initial exploration of the dataset.
"""

@mcp.prompt()
def explore_data_prompt():
    print("Registering explore_data_prompt")  # Add this line
    return [
        Prompt(
            name="explore-data",
            description="A prompt to explore a csv dataset as a data scientist",
            arguments=[
                PromptArgument(name="csv_path", description="The path to the csv file", required=True),
                PromptArgument(name="topic", description="The topic the data exploration need to focus on", required=False),
            ],
        )
    ]

@mcp.resource("data-exploration://notes")
def notes_resource():
    return [
        Resource(
            uri="data-exploration://notes",
            name="Data Exploration Notes",
            description="Notes generated by the data exploration server",
            mimeType="text/plain"
        )
    ]

if __name__ == "__main__":
    mcp.run(transport="streamable-http")
